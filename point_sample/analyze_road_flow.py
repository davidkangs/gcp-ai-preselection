#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„ë¡œ íë¦„ê³¼ ì—°ê²°ì„± ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ë„ë¡œì˜ ì‹¤ì œ íë¦„, ì»¤ë¸Œ, êµì°¨ì  ë“±ì„ ê³ ë ¤í•œ ì  ì¤‘ìš”ë„ ë¶„ì„
"""

import geopandas as gpd
import numpy as np
from shapely.geometry import Point, LineString
from shapely.ops import unary_union
import matplotlib.pyplot as plt
from scipy.spatial import KDTree
import networkx as nx
from sklearn.cluster import DBSCAN

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ì  ë°ì´í„° ë¡œë“œ
    points_gdf = gpd.read_file("p.geojson")
    print(f"âœ… ì  ë°ì´í„°: {len(points_gdf)}ê°œ ì ")
    
    # ë„ë¡œë§ ë°ì´í„° ë¡œë“œ
    road_gdf = gpd.read_file("road.geojson")
    print(f"âœ… ë„ë¡œë§ ë°ì´í„°: {len(road_gdf)}ê°œ í´ë¦¬ê³¤")
    
    return points_gdf, road_gdf

def extract_road_centerline(road_gdf):
    """ë„ë¡œ ì¤‘ì‹¬ì„  ì¶”ì¶œ"""
    print("ğŸ›£ï¸ ë„ë¡œ ì¤‘ì‹¬ì„  ì¶”ì¶œ ì¤‘...")
    
    # ë„ë¡œ í´ë¦¬ê³¤ í†µí•©
    road_union = unary_union(road_gdf.geometry)
    
    # ì¤‘ì‹¬ì„  ì¶”ì¶œ (ë‹¨ìˆœí™”ëœ ë°©ë²•)
    centerlines = []
    
    if hasattr(road_union, 'geoms'):
        # MultiPolygonì¸ ê²½ìš°
        for polygon in road_union.geoms:
            # ê²½ê³„ì„ ì„ ì¤‘ì‹¬ì„ ìœ¼ë¡œ ì‚¬ìš©
            boundary = polygon.boundary
            if hasattr(boundary, 'geoms'):
                for line in boundary.geoms:
                    centerlines.append(line)
            else:
                centerlines.append(boundary)
    else:
        # ë‹¨ì¼ Polygonì¸ ê²½ìš°
        boundary = road_union.boundary
        if hasattr(boundary, 'geoms'):
            for line in boundary.geoms:
                centerlines.append(line)
        else:
            centerlines.append(boundary)
    
    print(f"âœ… ì¤‘ì‹¬ì„ : {len(centerlines)}ê°œ")
    return centerlines

def analyze_road_curvature(centerlines, points_gdf, radius=30):
    """ë„ë¡œ ì»¤ë¸Œ ë¶„ì„"""
    print("ğŸ”„ ë„ë¡œ ì»¤ë¸Œ ë¶„ì„ ì¤‘...")
    
    curvature_scores = {}
    
    for idx, point in points_gdf.iterrows():
        point_geom = Point(point.geometry.x, point.geometry.y)
        point_buffer = point_geom.buffer(radius)
        
        # ë°˜ê²½ ë‚´ ì¤‘ì‹¬ì„  ì°¾ê¸°
        nearby_lines = []
        for line in centerlines:
            if line.intersects(point_buffer):
                nearby_lines.append(line)
        
        if not nearby_lines:
            curvature_scores[point['id']] = 0
            continue
        
        # ì»¤ë¸Œ ì ìˆ˜ ê³„ì‚°
        curvature_score = 0
        
        for line in nearby_lines:
            coords = list(line.coords)
            if len(coords) < 3:
                continue
            
            # ì—°ì†ëœ 3ì ìœ¼ë¡œ ê°ë„ ë³€í™” ê³„ì‚°
            angles = []
            for i in range(len(coords) - 2):
                p1, p2, p3 = coords[i], coords[i+1], coords[i+2]
                
                # ë²¡í„° ê³„ì‚°
                v1 = np.array([p2[0] - p1[0], p2[1] - p1[1]])
                v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])
                
                # ê°ë„ ê³„ì‚°
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                cos_angle = np.clip(cos_angle, -1, 1)
                angle = np.arccos(cos_angle)
                
                angles.append(angle)
            
            if angles:
                # í‰ê·  ê°ë„ ë³€í™” (ì»¤ë¸Œ ì •ë„)
                avg_angle_change = np.mean(angles)
                curvature_score += avg_angle_change
        
        curvature_scores[point['id']] = curvature_score
    
    return curvature_scores

def analyze_connectivity(points_gdf, centerlines, radius=50):
    """ë„ë¡œ ì—°ê²°ì„± ë¶„ì„"""
    print("ğŸ”— ë„ë¡œ ì—°ê²°ì„± ë¶„ì„ ì¤‘...")
    
    connectivity_scores = {}
    
    for idx, point in points_gdf.iterrows():
        point_geom = Point(point.geometry.x, point.geometry.y)
        point_buffer = point_geom.buffer(radius)
        
        # ë°˜ê²½ ë‚´ ì¤‘ì‹¬ì„  ì°¾ê¸°
        nearby_lines = []
        for line in centerlines:
            if line.intersects(point_buffer):
                nearby_lines.append(line)
        
        if len(nearby_lines) < 2:
            connectivity_scores[point['id']] = 0
            continue
        
        # ì—°ê²°ì„± ì ìˆ˜ ê³„ì‚°
        # 1. êµì°¨ì  ì—¬ë¶€ (ì—¬ëŸ¬ ì„ ì´ ë§Œë‚˜ëŠ” ì§€ì )
        intersection_count = 0
        for i, line1 in enumerate(nearby_lines):
            for j, line2 in enumerate(nearby_lines):
                if i < j:
                    if line1.intersects(line2):
                        intersection_count += 1
        
        # 2. ì„ ì˜ ë°©í–¥ ë‹¤ì–‘ì„±
        directions = []
        for line in nearby_lines:
            coords = list(line.coords)
            if len(coords) >= 2:
                # ì„ ì˜ ë°©í–¥ ë²¡í„°
                direction = np.array([coords[-1][0] - coords[0][0], 
                                    coords[-1][1] - coords[0][1]])
                if np.linalg.norm(direction) > 0:
                    direction = direction / np.linalg.norm(direction)
                    directions.append(direction)
        
        # ë°©í–¥ ë‹¤ì–‘ì„± ê³„ì‚°
        direction_diversity = 0
        if len(directions) >= 2:
            for i, dir1 in enumerate(directions):
                for j, dir2 in enumerate(directions):
                    if i < j:
                        angle = np.arccos(np.clip(np.dot(dir1, dir2), -1, 1))
                        direction_diversity += angle
        
        connectivity_score = intersection_count * 10 + direction_diversity * 5
        connectivity_scores[point['id']] = connectivity_score
    
    return connectivity_scores

def analyze_traffic_flow(points_gdf, centerlines, radius=40):
    """êµí†µ íë¦„ ë¶„ì„"""
    print("ğŸš— êµí†µ íë¦„ ë¶„ì„ ì¤‘...")
    
    flow_scores = {}
    
    for idx, point in points_gdf.iterrows():
        point_geom = Point(point.geometry.x, point.geometry.y)
        point_buffer = point_geom.buffer(radius)
        
        # ë°˜ê²½ ë‚´ ì¤‘ì‹¬ì„  ì°¾ê¸°
        nearby_lines = []
        for line in centerlines:
            if line.intersects(point_buffer):
                nearby_lines.append(line)
        
        if not nearby_lines:
            flow_scores[point['id']] = 0
            continue
        
        # êµí†µ íë¦„ ì ìˆ˜ ê³„ì‚°
        flow_score = 0
        
        for line in nearby_lines:
            # ì„ ì˜ ê¸¸ì´ (êµí†µëŸ‰ ì¶”ì •)
            line_length = line.length
            flow_score += line_length
            
            # ì„ ì˜ ë³µì¡ë„ (ì»¤ë¸Œ, êµì°¨ ë“±)
            coords = list(line.coords)
            if len(coords) >= 3:
                # ë°©í–¥ ë³€í™” íšŸìˆ˜
                direction_changes = 0
                for i in range(len(coords) - 2):
                    v1 = np.array([coords[i+1][0] - coords[i][0], 
                                  coords[i+1][1] - coords[i][1]])
                    v2 = np.array([coords[i+2][0] - coords[i+1][0], 
                                  coords[i+2][1] - coords[i+1][1]])
                    
                    if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0:
                        v1 = v1 / np.linalg.norm(v1)
                        v2 = v2 / np.linalg.norm(v2)
                        angle = np.arccos(np.clip(np.dot(v1, v2), -1, 1))
                        if angle > np.pi/6:  # 30ë„ ì´ìƒ ë³€í™”
                            direction_changes += 1
                
                flow_score += direction_changes * 5
        
        flow_scores[point['id']] = flow_score
    
    return flow_scores

def calculate_comprehensive_importance(points_gdf, road_gdf, centerlines):
    """ì¢…í•© ì¤‘ìš”ë„ ê³„ì‚°"""
    print("ğŸ¯ ì¢…í•© ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...")
    
    # ê¸°ì¡´ ì¤‘ìš”ë„ ê³„ì‚° (ë„ë¡œ í­ + ìŠ¤ì¼ˆë ˆí†¤ ë°€ë„)
    skeleton_points = extract_skeleton(road_gdf)
    
    results = []
    for idx, point in points_gdf.iterrows():
        coords = (point.geometry.x, point.geometry.y)
        
        # ê¸°ì¡´ ì¤‘ìš”ë„
        basic_importance = calculate_basic_importance(coords, road_gdf, skeleton_points)
        
        # ìƒˆë¡œìš´ ë¶„ì„ë“¤
        curvature_score = analyze_road_curvature(centerlines, points_gdf.iloc[[idx]], radius=30)[point['id']]
        connectivity_score = analyze_connectivity(points_gdf.iloc[[idx]], centerlines, radius=50)[point['id']]
        flow_score = analyze_traffic_flow(points_gdf.iloc[[idx]], centerlines, radius=40)[point['id']]
        
        # ì¢…í•© ì¤‘ìš”ë„ (ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥)
        comprehensive_importance = (
            basic_importance['importance'] * 0.3 +  # ê¸°ì¡´ ì¤‘ìš”ë„
            curvature_score * 0.2 +                # ì»¤ë¸Œ ì¤‘ìš”ë„
            connectivity_score * 0.3 +             # ì—°ê²°ì„± ì¤‘ìš”ë„
            flow_score * 0.2                       # êµí†µ íë¦„ ì¤‘ìš”ë„
        )
        
        results.append({
            "id": point['id'],
            "coords": coords,
            "basic_importance": basic_importance['importance'],
            "curvature_score": curvature_score,
            "connectivity_score": connectivity_score,
            "flow_score": flow_score,
            "comprehensive_importance": comprehensive_importance
        })
        
        print(f"\nğŸ¯ {point['id']}ë²ˆ ì  ì¢…í•© ë¶„ì„:")
        print(f"  - ê¸°ì¡´ ì¤‘ìš”ë„: {basic_importance['importance']:.1f}")
        print(f"  - ì»¤ë¸Œ ì ìˆ˜: {curvature_score:.1f}")
        print(f"  - ì—°ê²°ì„± ì ìˆ˜: {connectivity_score:.1f}")
        print(f"  - êµí†µ íë¦„ ì ìˆ˜: {flow_score:.1f}")
        print(f"  - ì¢…í•© ì¤‘ìš”ë„: {comprehensive_importance:.1f}")
    
    return results

def extract_skeleton(road_gdf, sample_distance=5.0):
    """ë„ë¡œë§ì—ì„œ ìŠ¤ì¼ˆë ˆí†¤ ì¶”ì¶œ"""
    road_union = unary_union(road_gdf.geometry)
    skeleton_points = []
    
    if hasattr(road_union, 'geoms'):
        for polygon in road_union.geoms:
            boundary = polygon.boundary
            if hasattr(boundary, 'geoms'):
                for line in boundary.geoms:
                    coords = list(line.coords)
                    for i in range(0, len(coords), int(sample_distance)):
                        if i < len(coords):
                            skeleton_points.append(coords[i])
            else:
                coords = list(boundary.coords)
                for i in range(0, len(coords), int(sample_distance)):
                    if i < len(coords):
                        skeleton_points.append(coords[i])
    else:
        boundary = road_union.boundary
        if hasattr(boundary, 'geoms'):
            for line in boundary.geoms:
                coords = list(line.coords)
                for i in range(0, len(coords), int(sample_distance)):
                    if i < len(coords):
                        skeleton_points.append(coords[i])
        else:
            coords = list(boundary.coords)
            for i in range(0, len(coords), int(sample_distance)):
                if i < len(coords):
                    skeleton_points.append(coords[i])
    
    return skeleton_points

def calculate_basic_importance(point, road_gdf, skeleton_points, radius=15):
    """ê¸°ë³¸ ì¤‘ìš”ë„ ê³„ì‚°"""
    point_geom = Point(point)
    
    min_distance = float('inf')
    nearest_road = None
    
    for idx, road in road_gdf.iterrows():
        distance = point_geom.distance(road.geometry)
        if distance < min_distance:
            min_distance = distance
            nearest_road = road.geometry
    
    if nearest_road is None:
        return {"importance": 0, "road_width": 0, "skeleton_density": 0}
    
    point_buffer = point_geom.buffer(radius)
    local_road = nearest_road.intersection(point_buffer)
    
    if local_road.is_empty:
        road_width = 0
    else:
        road_width = local_road.area / max(local_road.length, 1)
    
    skeleton_tree = KDTree(skeleton_points)
    nearby_skeleton = skeleton_tree.query_ball_point(point, radius)
    skeleton_density = len(nearby_skeleton) / (np.pi * radius**2)
    
    importance = (road_width * 10) + (skeleton_density * 1000)
    
    return {
        "importance": importance,
        "road_width": road_width,
        "skeleton_density": skeleton_density,
        "min_distance_to_road": min_distance
    }

def analyze_all_points_with_flow():
    """ë„ë¡œ íë¦„ì„ ê³ ë ¤í•œ ì „ì²´ ì  ë¶„ì„"""
    print("\nğŸ” ë„ë¡œ íë¦„ ê¸°ë°˜ ë¶„ì„ ì‹œì‘...")
    
    # ë°ì´í„° ë¡œë“œ
    points_gdf, road_gdf = load_data()
    
    # ì¤‘ì‹¬ì„  ì¶”ì¶œ
    centerlines = extract_road_centerline(road_gdf)
    
    # ì¢…í•© ì¤‘ìš”ë„ ê³„ì‚°
    results = calculate_comprehensive_importance(points_gdf, road_gdf, centerlines)
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_results = sorted(results, key=lambda x: x['comprehensive_importance'], reverse=True)
    
    print(f"\nğŸ† ì¢…í•© ì¤‘ìš”ë„ ìˆœìœ„:")
    for i, result in enumerate(sorted_results):
        print(f"  {i+1}ìœ„: {result['id']}ë²ˆ ì  (ì¢…í•© ì¤‘ìš”ë„ {result['comprehensive_importance']:.1f})")
    
    # í´ëŸ¬ìŠ¤í„°ë§ ì‹œë®¬ë ˆì´ì…˜
    print(f"\nğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ì‹œë®¬ë ˆì´ì…˜ (20m ì„ê³„ê°’):")
    
    clusters = []
    used = set()
    
    for i, p1 in enumerate(sorted_results):
        if i in used:
            continue
            
        cluster = [p1]
        used.add(i)
        
        print(f"\nğŸ“Œ ê¸°ì¤€ì  {p1['id']}ë²ˆ (ì¢…í•© ì¤‘ìš”ë„ {p1['comprehensive_importance']:.1f}):")
        
        for j, p2 in enumerate(sorted_results):
            if j in used:
                continue
                
            dist = Point(p1['coords']).distance(Point(p2['coords']))
            
            if dist <= 20.0:
                cluster.append(p2)
                used.add(j)
                print(f"  âœ… {p2['id']}ë²ˆ ì  í¬í•¨ (ê±°ë¦¬ {dist:.1f}m, ì¢…í•© ì¤‘ìš”ë„ {p2['comprehensive_importance']:.1f})")
            else:
                print(f"  âŒ {p2['id']}ë²ˆ ì  ì œì™¸ (ê±°ë¦¬ {dist:.1f}m, ì¢…í•© ì¤‘ìš”ë„ {p2['comprehensive_importance']:.1f})")
        
        if len(cluster) > 1:
            clusters.append(cluster)
            print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° {len(clusters)} ìƒì„±: {len(cluster)}ê°œ ì ")
        else:
            print(f"ğŸ“Œ ë‹¨ë… ì : í´ëŸ¬ìŠ¤í„° ìƒì„± ì•ˆí•¨")
    
    # ê²°ê³¼ ìš”ì•½
    all_removed = []
    all_selected = []
    
    for i, cluster in enumerate(clusters):
        best_point = max(cluster, key=lambda x: x['comprehensive_importance'])
        removed_points = [p for p in cluster if p != best_point]
        
        all_selected.append(best_point)
        all_removed.extend(removed_points)
        
        print(f"\ní´ëŸ¬ìŠ¤í„° {i+1}:")
        print(f"  ğŸ† ì„ íƒ: {best_point['id']}ë²ˆ ì  (ì¢…í•© ì¤‘ìš”ë„ {best_point['comprehensive_importance']:.1f})")
        for removed in removed_points:
            print(f"  ğŸ—‘ï¸ ì‚­ì œ: {removed['id']}ë²ˆ ì  (ì¢…í•© ì¤‘ìš”ë„ {removed['comprehensive_importance']:.1f})")
    
    # ë‹¨ë… ì ë“¤
    single_points = [p for p in sorted_results if not any(p in cluster for cluster in clusters)]
    all_selected.extend(single_points)
    
    if single_points:
        print(f"\nğŸ“Œ ë‹¨ë… ì ë“¤ (ì‚­ì œ ì•ˆë¨):")
        for point in single_points:
            print(f"  âœ… {point['id']}ë²ˆ ì  (ì¢…í•© ì¤‘ìš”ë„ {point['comprehensive_importance']:.1f})")
    
    print(f"\nğŸ“‹ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
    print(f"  ğŸ† ìœ ì§€ë˜ëŠ” ì : {[p['id'] for p in all_selected]}")
    print(f"  ğŸ—‘ï¸ ì‚­ì œë˜ëŠ” ì : {[p['id'] for p in all_removed]}")
    
    return results, clusters, all_removed

if __name__ == "__main__":
    print("ğŸš€ ë„ë¡œ íë¦„ ê¸°ë°˜ ì¤‘ìš”ë„ ë¶„ì„ ì‹œì‘!")
    print("=" * 50)
    
    results, clusters, removed_points = analyze_all_points_with_flow()
    
    print("\n" + "=" * 50)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ’¡ ê²°ë¡ :")
    print("1. ë„ë¡œ íë¦„, ì»¤ë¸Œ, ì—°ê²°ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤")
    print("2. êµí†µìƒ í•„ìˆ˜ì ì¸ ì ë“¤ë„ ì¤‘ìš”ë„ì— ë°˜ì˜")
    print("3. ë‹¨ìˆœíˆ ë„ë¡œ í­/ë°€ë„ë§Œì´ ì•„ë‹Œ ì‹¤ì œ êµí†µ ê¸°ëŠ¥ ê³ ë ¤") 