"""
ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
ì´ íŒŒì¼ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ìµœì í™”ëœ ì„¤ì • ì‚¬ìš©
"""

FAST_TRAINING_CONFIG = {
    'epochs': 20,
    'batch_size': 256,
    'learning_rate': 0.003,
    'hidden_sizes': [128, 64],
    'early_stopping': True,
    'early_stopping_patience': 5,
    'gradient_clip': 1.0,
    'use_amp': True  # Automatic Mixed Precision
}

# GPU ìµœì í™”
import torch
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.enabled = True
    
    # ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”
    torch.cuda.empty_cache()
    
    print(f"ğŸš€ GPU ìµœì í™” í™œì„±í™”: {torch.cuda.get_device_name(0)}")
    print(f"   ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

print("âš¡ ë¹ ë¥¸ í•™ìŠµ ëª¨ë“œ í™œì„±í™”ë¨!")
print(f"   ì„¤ì •: {FAST_TRAINING_CONFIG}")
