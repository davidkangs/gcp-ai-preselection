# ğŸš€ CUDA PyTorch ì—…ê·¸ë ˆì´ë“œ ê°€ì´ë“œ

## ğŸ“‹ í˜„ì¬ í™˜ê²½ ì •ë³´
- **Python**: 3.11.4
- **PyTorch**: 2.1.0 (CPU ë²„ì „)
- **GPU**: NVIDIA RTX A6000 (48GB VRAM)
- **CUDA ë“œë¼ì´ë²„**: 12.8
- **OS**: Windows 10

## ğŸ¯ ëª©í‘œ
CPU ì „ìš© PyTorchë¥¼ CUDA ì§€ì› ë²„ì „ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì—…ê·¸ë ˆì´ë“œ

## âš ï¸ ì‚¬ì „ í™•ì¸ì‚¬í•­

### 1. GPU ë° ë“œë¼ì´ë²„ í™•ì¸
```bash
nvidia-smi
```
**í™•ì¸í•  ê²ƒ:** CUDA Versionì´ í‘œì‹œë˜ëŠ”ì§€

### 2. í˜„ì¬ PyTorch ë²„ì „ í™•ì¸
```bash
python -c "import torch; print('Version:', torch.__version__); print('CUDA:', torch.cuda.is_available())"
```
**ì˜ˆìƒ ê²°ê³¼:** Version: 2.1.0, CUDA: False

## ğŸ”§ ì—…ê·¸ë ˆì´ë“œ ì ˆì°¨

### 1ë‹¨ê³„: í™˜ê²½ ë°±ì—… (í•„ìˆ˜!)
```bash
# í˜„ì¬ ë””ë ‰í† ë¦¬: I:\gcp_rl
pip freeze > cuda_upgrade_backup.txt
```

### 2ë‹¨ê³„: ê¸°ì¡´ PyTorch ì œê±°
```bash
pip uninstall torch torchvision torchaudio -y
```

### 3ë‹¨ê³„: CUDA PyTorch ì„¤ì¹˜
```bash
# ë™ì¼í•œ ë²„ì „ + CUDA 12.1
pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html
```

### 4ë‹¨ê³„: ì„¤ì¹˜ í™•ì¸
```bash
python -c "import torch; print('Version:', torch.__version__); print('CUDA available:', torch.cuda.is_available()); print('GPU name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')"
```

**ê¸°ëŒ€ ê²°ê³¼:**
```
Version: 2.1.0+cu121
CUDA available: True
GPU name: NVIDIA RTX A6000
```

### 5ë‹¨ê³„: í”„ë¡œì íŠ¸ í…ŒìŠ¤íŠ¸
```bash
python test_installation.py
```
**í™•ì¸í•  ê²ƒ:** GPU ì§€ì› í•­ëª©ì´ âœ…ë¡œ í‘œì‹œë˜ëŠ”ì§€

## ğŸ”„ ë¬¸ì œ ë°œìƒ ì‹œ ë¡¤ë°±

### ì›ë˜ ìƒíƒœë¡œ ë³µêµ¬
```bash
# CUDA ë²„ì „ ì œê±°
pip uninstall torch torchvision torchaudio -y

# CPU ë²„ì „ ì¬ì„¤ì¹˜
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0

# ë˜ëŠ” ë°±ì—…ì—ì„œ ë³µì›
pip install -r cuda_upgrade_backup.txt --force-reinstall
```

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ì˜ˆìƒì¹˜

### RTX A6000 ê¸°ëŒ€ ì„±ëŠ¥
- **í•™ìŠµ ì†ë„**: 10-100ë°° ë¹¨ë¼ì§
- **ë©”ëª¨ë¦¬**: 48GB VRAM í™œìš© ê°€ëŠ¥
- **ë°°ì¹˜ í¬ê¸°**: 64 â†’ 512+ ì¦ê°€ ê°€ëŠ¥
- **ì¶”ë¡  ì‹œê°„**: 10ì´ˆ â†’ 1ì´ˆ ë¯¸ë§Œ

### Processë³„ ê°œì„ 
- **Process2 (í•™ìŠµ)**: 1ì‹œê°„ â†’ 5-10ë¶„
- **Process3 (AI ì˜ˆì¸¡)**: 10ì´ˆ â†’ 1ì´ˆ ë¯¸ë§Œ
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œê°„ ëŒ€í­ ë‹¨ì¶•

## ğŸ” ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. "CUDA out of memory" ì˜¤ë¥˜
```python
# í•´ê²°ë°©ë²•: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
# configs/dqn_config.pyì—ì„œ
'batch_size': 32,  # 64 â†’ 32ë¡œ ê°ì†Œ
```

#### 2. CUDA ë²„ì „ ë¶ˆì¼ì¹˜
```bash
# ë‹¤ë¥¸ CUDA ë²„ì „ ì‹œë„
pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html
```

#### 3. ë‹¤ë¥¸ íŒ¨í‚¤ì§€ ì¶©ëŒ
```bash
# ì „ì²´ í™˜ê²½ ì¬êµ¬ì„±
pip install -r requirements.txt --force-reinstall
```

## âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] nvidia-smi ì •ìƒ ì‘ë™
- [ ] ë°±ì—… íŒŒì¼ ìƒì„±ë¨
- [ ] PyTorch CUDA ë²„ì „ ì„¤ì¹˜ë¨
- [ ] torch.cuda.is_available() == True
- [ ] GPU ì´ë¦„ ì •ìƒ ì¶œë ¥ë¨
- [ ] test_installation.py í†µê³¼
- [ ] Process3 ëª¨ë¸ ë¡œë“œ ì„±ê³µ

## ğŸ“ ë²„ì „ í˜¸í™˜ì„± ì°¸ê³ 

| PyTorch | Python | CUDA | ê²€ì¦ ìƒíƒœ |
|---------|--------|------|----------|
| 2.1.0+cu121 | 3.11.4 | 12.1 | âœ… ê¶Œì¥ |
| 2.1.0+cu118 | 3.11.4 | 11.8 | âœ… ì•ˆì „ |
| 2.2.0+cu121 | 3.11.4 | 12.1 | âš ï¸ ë¯¸ê²€ì¦ |

## ğŸ‰ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ í›„

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```bash
# GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
nvidia-smi -l 1
```

### ì„¤ì • ìµœì í™”
```python
# configs/dqn_config.pyì—ì„œ
'device': 'cuda',  # 'auto' â†’ 'cuda'ë¡œ ê°•ì œ ì„¤ì •
'batch_size': 256,  # í° ë°°ì¹˜ í¬ê¸° í™œìš©
```

---

**ì‘ì„±ì¼**: 2025ë…„ 1ì›” 20ì¼  
**í™˜ê²½**: Python 3.11.4, RTX A6000, Windows 10  
**ìƒíƒœ**: í…ŒìŠ¤íŠ¸ ì™„ë£Œ 