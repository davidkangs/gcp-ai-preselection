"""
laptop_optimization.py - λ…ΈνΈλ¶ ν™κ²½ μµμ ν™” μ„¤μ •
μ‹μ—°μ© μ €μ‚¬μ–‘ ν™κ²½μ—μ„μ μ›ν™ν• μ‹¤ν–‰μ„ μ„ν• μ„¤μ •
"""

import json
import torch
import psutil
from pathlib import Path

def create_laptop_config():
    """λ…ΈνΈλ¶μ© μµμ ν™” μ„¤μ • μƒμ„±"""
    
    # μ‹μ¤ν… μ •λ³΄ ν™•μΈ
    ram_gb = psutil.virtual_memory().total / (1024**3)
    cpu_count = psutil.cpu_count(logical=False)
    has_gpu = torch.cuda.is_available()
    
    print(f"μ‹μ¤ν… μ •λ³΄:")
    print(f"- RAM: {ram_gb:.1f} GB")
    print(f"- CPU μ½”μ–΄: {cpu_count}κ°")
    print(f"- GPU: {'μμ' if has_gpu else 'μ—†μ'}")
    
    # μµμ ν™” μ„¤μ •
    if ram_gb < 8:
        # μ €μ‚¬μ–‘
        config = {
            "batch_size": 16,
            "epochs": 20,
            "skeleton_max_points": 3000,
            "network_size": "small",
            "num_workers": 1
        }
        print("\nβ οΈ μ €μ‚¬μ–‘ λ¨λ“ μ„¤μ •")
    elif ram_gb < 16:
        # μ¤‘κ°„ μ‚¬μ–‘
        config = {
            "batch_size": 32,
            "epochs": 30,
            "skeleton_max_points": 5000,
            "network_size": "medium",
            "num_workers": 2
        }
        print("\nβ„ΉοΈ μ¤‘κ°„ μ‚¬μ–‘ λ¨λ“ μ„¤μ •")
    else:
        # κ³ μ‚¬μ–‘
        config = {
            "batch_size": 64,
            "epochs": 50,
            "skeleton_max_points": 10000,
            "network_size": "large",
            "num_workers": 4
        }
        print("\nβ… κ³ μ‚¬μ–‘ λ¨λ“ μ„¤μ •")
    
    # GPU μ„¤μ •
    if has_gpu:
        # GPU λ©”λ¨λ¦¬ ν™•μΈ
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        if gpu_memory < 4:
            config["batch_size"] = min(config["batch_size"], 16)
            print(f"GPU λ©”λ¨λ¦¬ {gpu_memory:.1f}GB - λ°°μΉ ν¬κΈ° μ ν•")
    else:
        config["use_gpu"] = False
        config["batch_size"] = min(config["batch_size"], 32)
        print("CPU λ¨λ“ - λ°°μΉ ν¬κΈ° μ ν•")
    
    # μ „μ²΄ μ„¤μ •
    full_config = {
        "system_info": {
            "ram_gb": ram_gb,
            "cpu_cores": cpu_count,
            "has_gpu": has_gpu,
            "optimized_for": "laptop_demo"
        },
        "learning": {
            "batch_size": config["batch_size"],
            "epochs": config["epochs"],
            "learning_rate": 0.001,
            "action_size": 4,
            "state_size": 7,
            "network_size": config.get("network_size", "small"),
            "hidden_sizes": {
                "small": [128, 64],
                "medium": [256, 128, 64],
                "large": [512, 256, 128, 64]
            }[config.get("network_size", "small")]
        },
        "ui": {
            "skeleton_max_points": config["skeleton_max_points"],
            "skeleton_sampling_rate": 1 if config["skeleton_max_points"] >= 5000 else 2,
            "antialiasing": False,  # μ„±λ¥μ„ μ„ν•΄ λΉ„ν™μ„±ν™”
            "road_opacity": 0.5,
            "update_mode": "smart",  # μ¤λ§νΈ μ—…λ°μ΄νΈ
            "cache_mode": True       # μΊμ‹± ν™μ„±ν™”
        },
        "performance": {
            "use_gpu": config.get("use_gpu", has_gpu),
            "num_workers": config["num_workers"],
            "prefetch_factor": 2,
            "persistent_workers": False,  # λ©”λ¨λ¦¬ μ μ•½
            "pin_memory": has_gpu and ram_gb >= 8
        },
        "demo_mode": {
            "enabled": True,
            "auto_save": False,  # μ‹μ—° μ¤‘ μλ™ μ €μ¥ λΉ„ν™μ„±ν™”
            "show_fps": False,   # FPS ν‘μ‹ λΉ„ν™μ„±ν™”
            "simplified_ui": True # λ‹¨μν™”λ UI
        }
    }
    
    # μ €μ¥
    with open("laptop_config.json", 'w', encoding='utf-8') as f:
        json.dump(full_config, f, indent=2, ensure_ascii=False)
    
    print(f"\nμ„¤μ • μ €μ¥ μ™„λ£: laptop_config.json")
    print(f"\nκ¶μ¥ μ„¤μ •:")
    print(f"- λ°°μΉ ν¬κΈ°: {config['batch_size']}")
    print(f"- μ—ν­: {config['epochs']}")
    print(f"- μµλ€ μ¤μΌλ ν†¤ ν¬μΈνΈ: {config['skeleton_max_points']}")
    
    return full_config

def apply_laptop_config():
    """λ…ΈνΈλ¶ μ„¤μ • μ μ©"""
    
    config_file = Path("laptop_config.json")
    if not config_file.exists():
        print("μ„¤μ • νμΌμ΄ μ—†μµλ‹λ‹¤. μƒμ„±ν•©λ‹λ‹¤...")
        config = create_laptop_config()
    else:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # Process 2 μ„¤μ • νμΌ μƒμ„±
    process2_config = {
        "batch_size": config["learning"]["batch_size"],
        "epochs": config["learning"]["epochs"],
        "learning_rate": config["learning"]["learning_rate"],
        "network_size": config["learning"]["network_size"]
    }
    
    with open("process2_laptop_config.json", 'w', encoding='utf-8') as f:
        json.dump(process2_config, f, indent=2)
    
    print("\nβ… λ…ΈνΈλ¶ μµμ ν™” μ„¤μ •μ΄ μ μ©λμ—μµλ‹λ‹¤!")
    
    # μ¶”κ°€ ν
    print("\nπ’΅ μ‹μ—° ν:")
    print("1. μ‘μ€ shapefileλ΅ μ‹μ‘ (1-2MB)")
    print("2. λ°°ν„°λ¦¬ μ μ•½ λ¨λ“ ν•΄μ ")
    print("3. λ¶ν•„μ”ν• ν”„λ΅κ·Έλ¨ μΆ…λ£")
    print("4. ν•™μµ μ „ GPU λ©”λ¨λ¦¬ μ •λ¦¬:")
    print("   import torch")
    print("   torch.cuda.empty_cache()")
    
    return config

def quick_performance_test():
    """λΉ λ¥Έ μ„±λ¥ ν…μ¤νΈ"""
    import time
    import numpy as np
    
    print("\nλΉ λ¥Έ μ„±λ¥ ν…μ¤νΈ μ¤‘...")
    
    # CPU ν…μ¤νΈ
    start = time.time()
    a = np.random.rand(1000, 1000)
    b = np.random.rand(1000, 1000)
    c = np.dot(a, b)
    cpu_time = time.time() - start
    print(f"CPU ν–‰λ ¬κ³± (1000x1000): {cpu_time:.3f}μ΄")
    
    # GPU ν…μ¤νΈ
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        start = time.time()
        a = torch.rand(1000, 1000).cuda()
        b = torch.rand(1000, 1000).cuda()
        c = torch.matmul(a, b)
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        print(f"GPU ν–‰λ ¬κ³± (1000x1000): {gpu_time:.3f}μ΄")
        print(f"GPU κ°€μ†: {cpu_time/gpu_time:.1f}λ°°")
    
    # κ¶μ¥μ‚¬ν•­
    if cpu_time > 0.5:
        print("\nβ οΈ CPU μ„±λ¥μ΄ λ‚®μµλ‹λ‹¤. λ°°μΉ ν¬κΈ°λ¥Ό μ¤„μ΄μ„Έμ”.")
    else:
        print("\nβ… CPU μ„±λ¥μ΄ μ μ ν•©λ‹λ‹¤.")

if __name__ == "__main__":
    print("=" * 60)
    print("λ…ΈνΈλ¶ ν™κ²½ μµμ ν™” λ„κµ¬")
    print("=" * 60)
    
    # μ„¤μ • μƒμ„± λ° μ μ©
    config = apply_laptop_config()
    
    # μ„±λ¥ ν…μ¤νΈ
    print("\nμ„±λ¥ ν…μ¤νΈλ¥Ό μ‹¤ν–‰ν•μ‹κ² μµλ‹κΉ? (y/n)")
    if input().lower() == 'y':
        quick_performance_test()
    
    print("\nμ™„λ£! μ΄μ  μ‹μ¤ν…μ„ μ‹¤ν–‰ν•  μ¤€λΉ„κ°€ λμ—μµλ‹λ‹¤.")
    print("python main_launcher.py")